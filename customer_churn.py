# -*- coding: utf-8 -*-
"""Customer Churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DwxNFSP7cfWPU-YIUW2sh5YDwKKZTuPk
"""

from google.colab import drive
drive.mount('/content/gdrive')

#Importing Libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import csv
import matplotlib as mat

from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.cluster import KMeans
from sklearn.cluster import AgglomerativeClustering
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_selection import RFECV
from sklearn.metrics import classification_report
from sklearn.model_selection import GridSearchCV

import warnings
warnings.filterwarnings('ignore')

#Data Collection
path = '/content/gdrive/MyDrive/E Commerce Dataset.csv'
data = pd.read_csv(path)

data.head()

data.columns

data.info()

data.describe()

#Null Values
plt.figure(figsize=(10,10))
plt.barh(missing_value_data['column_name'], missing_value_data['percent_missing'])
plt.tick_params(axis='y', which='both', length=0)
plt.title('Missing Data Percentage')
plt.show()

data['PreferredPaymentMode'].unique()

data['PreferredPaymentMode'] = data['PreferredPaymentMode'].str.replace('Cash on Delivery','COD')
data['PreferredPaymentMode'] = data['PreferredPaymentMode'].str.replace('Credit Card','CC')

binary_cat_cols = ['Complain']
outcome = ['Churn']
cat_cols = ['PreferredLoginDevice','Gender','PreferedOrderCat','MaritalStatus','CityTier']
num_cols = ['Tenure','WarehouseToHome','HourSpendOnApp','NumberOfDeviceRegistered','SatisfactionScore','NumberOfAddress','OrderAmountHikeFromlastYear',
           'CouponUsed','OrderCount','DaySinceLastOrder','CashbackAmount']

data.Churn.mean()

#Data Visulization
fig, ax = plt.subplots(3,4,figsize=(20, 18))
fig.suptitle('Numeric Features Distribution by Churn', fontsize=20)
ax = ax.flatten()
for idx,c in enumerate(num_cols):
    df_t = data[data[c].notnull()].copy()
    ax[idx].set_title(c)
    sns.boxplot(x='Churn', y=c, data=df_t, ax=ax[idx])
    ax[idx].set_ylabel('')
plt.show()

#Heat Map
corr = data.corr()
plt.figure(figsize=(10,10))
sns.heatmap(corr, annot=True, cmap="coolwarm")

df_c = data[data['Churn']==1].copy()
df_nc = data[data['Churn']==0].copy()

fig, ax = plt.subplots(3,4,figsize=(20, 18))
fig.suptitle('Numeric Features Density by Churn', fontsize=20)
ax = ax.flatten()

for idx,c in enumerate(num_cols):
    sns.kdeplot(df_c[c], linewidth= 3,
             label = 'Churn',ax=ax[idx])
    sns.kdeplot(df_nc[c], linewidth= 3,
             label = 'No Churn',ax=ax[idx])

    ax[idx].legend(loc='upper right')

plt.show()

fig, ax = plt.subplots(3,2,figsize=(20, 15))
fig.suptitle('Churn Percentage of Categorical Features', fontsize=20)
ax = ax.flatten()

for idx,c in enumerate(cat_cols+binary_cat_cols):
    data.groupby(c).Churn.mean().plot.barh(ax=ax[idx])
    ax[idx].set_xlabel('Churn Percentage')
plt.show()

hist = data.hist()

#Impute Missing Values (Replacing null values with median)
data[num_cols] = data[num_cols].fillna(data[num_cols].median())

#removing Outliers
def remove_outlier(data, col):
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR=Q3-Q1
    lr= Q1-(1.5 * IQR)
    ur= Q3+(1.5 * IQR)

    data[col]=np.where(data[col]>ur,ur,data[col])
    data[col]=np.where(data[col]<lr,lr,data[col])

    return data

for c in num_cols:
    data = remove_outlier(data, c)

#Exporting updated file
data.to_csv('eCommerce updated.csv')

#One Hot Encoding
#Removing Spaces & Special Chracters
data = data.replace(' ', '_', regex=True)
data = data.replace('&', 'And', regex=True)
data_encoded = pd.get_dummies(data,drop_first=True)
data_encoded.columns

#Spliting Dataset in 80(Train) 20(Test)
X = data_encoded[['Tenure', 'CityTier', 'WarehouseToHome',
       'HourSpendOnApp', 'NumberOfDeviceRegistered', 'SatisfactionScore',
       'NumberOfAddress', 'Complain', 'OrderAmountHikeFromlastYear',
       'CouponUsed', 'OrderCount', 'DaySinceLastOrder', 'CashbackAmount',
       'PreferredLoginDevice_Mobile_Phone', 'PreferredLoginDevice_Phone',
       'PreferredPaymentMode_COD', 'PreferredPaymentMode_Debit_Card',
       'PreferredPaymentMode_E_wallet', 'PreferredPaymentMode_UPI',
       'Gender_Male', 'PreferedOrderCat_Grocery',
       'PreferedOrderCat_Laptop_And_Accessory', 'PreferedOrderCat_Mobile',
       'PreferedOrderCat_Mobile_Phone', 'PreferedOrderCat_Others',
       'MaritalStatus_Married', 'MaritalStatus_Single']].copy()
y = data_encoded['Churn']
X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, random_state=42)

#Min Max Scaling
norm = MinMaxScaler().fit(X_train)
X_train_norm = norm.transform(X_train)
X_test_norm = norm.transform(X_test)

rfc = RandomForestClassifier(random_state=42)
rfc.fit(X_train, y_train)

print(type(rfc))
scores = cross_val_score(rfc,X_train,y_train,cv=5, scoring='roc_auc')
print ("Random Forest Efficiency:",scores.mean())
rfc.fit(X_train, y_train)
pred = rfc.predict(X_test)
print(classification_report(y_test, pred))

dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)
pred_dt = dt.predict(X_test)
scores_dt = cross_val_score(dt, X_train, y_train, cv=5, scoring='roc_auc')
efficiency_dt = scores_dt.mean()
print("Decision Tree Efficiency: ", efficiency_dt)
print(classification_report(y_test, pred_dt))

adaboost = AdaBoostClassifier(random_state=42)
adaboost.fit(X_train, y_train)

print(type(adaboost))

scores_adaboost = cross_val_score(adaboost, X_train, y_train, cv=5, scoring='roc_auc')
efficiency_adaboost = scores_adaboost.mean()
print("AdaBoost Efficiency:", efficiency_adaboost)

pred_adaboost = adaboost.predict(X_test)

print(classification_report(y_test, pred_adaboost))

hierarchical = AgglomerativeClustering(n_clusters=2)
hierarchical.fit(X_train)

silhouette_avg = silhouette_score(X_train, hierarchical.labels_)

print("Hierarchical Clustering Efficiency (Silhouette Coefficient):", silhouette_avg)

kmeans = KMeans(n_clusters=2, random_state=42)
kmeans.fit(X_train)

from sklearn.metrics import silhouette_score
silhouette_avg = silhouette_score(X_train, kmeans.labels_)

print("K-means Clustering Efficiency (Silhouette Coefficient):", silhouette_avg)

svm = SVC(random_state=42)
svm.fit(X_train, y_train)

print(type(svm))

scores_svm = cross_val_score(svm, X_train, y_train, cv=5, scoring='roc_auc')
efficiency_svm = scores_svm.mean()
print("SVM Efficiency:", efficiency_svm)

pred_svm = svm.predict(X_test)

print(classification_report(y_test, pred_svm))

lr = LogisticRegression(random_state=42)
lr.fit(X_train, y_train)

print(type(lr))
scores = cross_val_score(lr,X_train,y_train,cv=5,scoring='roc_auc')
print ("Logistic Regression Efficiency:",scores.mean())
lr.fit(X_train, y_train)
pred = lr.predict(X_test)
print(classification_report(y_test, pred))

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense


model = Sequential()
model.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)
loss, accuracy = model.evaluate(X_test, y_test)

print("Final ANN Accuracy:", accuracy)

y_pred_ann = model.predict(X_test)
y_pred_ann = [1 if pred >= 0.5 else 0 for pred in y_pred_ann]
print(classification_report(y_test, y_pred_ann))

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report
from sklearn.model_selection import cross_val_score

nb = GaussianNB()
nb.fit(X_train_norm, y_train)
pred_nb = nb.predict(X_test_norm)
scores_nb = cross_val_score(nb, X_train_norm, y_train, cv=5, scoring='roc_auc')
efficiency_nb = scores_nb.mean()

print("Naive Bayes Efficiency:", efficiency_nb)
print(classification_report(y_test, pred_nb))